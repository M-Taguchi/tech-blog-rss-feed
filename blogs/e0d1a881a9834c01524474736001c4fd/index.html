<!doctype html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="author" content="yamadashy"><meta name="robots" content="index, follow"><meta property="og:url" content="https://yamadashy.github.io/tech-blog-rss-feed/"><meta property="og:title" content="Stockmark Tech Blogのフィード｜企業テックブログRSS"><meta property="og:image" content="https://yamadashy.github.io/tech-blog-rss-feed/images/og-image.png"><meta property="og:description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta property="og:type" content="website"><meta property="og:site_name" content="企業テックブログRSS"><meta name="twitter:card" content="summary"><meta property="twitter:domain" content="https://yamadashy.github.io/tech-blog-rss-feed/"><meta property="twitter:url" 
content="https://yamadashy.github.io/tech-blog-rss-feed/"><meta name="twitter:title" content="Stockmark Tech Blogのフィード｜企業テックブログRSS"><meta name="twitter:description" content="企業のテックブログの更新をまとめたRSSフィードを配信しています。記事を読んでその企業の技術・カルチャーを知れることや、質の高い技術情報を得られることを目的としています。"><meta name="twitter:image" content="https://yamadashy.github.io/tech-blog-rss-feed/images/og-image.png"><meta name="google-site-verification" content="GPLvXv8kYtLMW912ZS54DKFEZL6ruOrjOFLdHVTo37o"><link rel="shortcut icon" href="../../images/favicon.ico"><link rel="apple-touch-icon" href="../../images/apple-icon.png"><link rel="alternate" type="application/atom+xml" title="Atom Feed" href="../../feeds/atom.xml"><link rel="alternate" type="application/rss+xml" title="RSS2.0" href="../../feeds/rss.xml"><link rel="alternate" type="application/json" href="../../feeds/feed.json"><style>
*,::after,::before{box-sizing:border-box}*{margin:0}body,html{height:100%}body{line-height:1.5;-webkit-font-smoothing:antialiased}canvas,img,picture,svg,video{display:block;max-width:100%}button,input,select,textarea{font:inherit}h1,h2,h3,h4,h5,h6,p{overflow-wrap:break-word}#__next,#root{isolation:isolate}:root{--ui-color-brand:#353535;--ui-color-n-000:#fff;--ui-color-n-100:#ebebeb;--ui-color-n-300:#aeaeae;--ui-color-n-500:#353535;--ui-color-n-700:#282828;--ui-color-n-900:#1a1a1a;--ui-color-background-primary:var(--ui-color-n-000);--ui-color-form-input:var(--ui-color-n-100);--ui-color-typography-heading:var(--ui-color-n-500);--ui-color-typography-body:var(--ui-color-n-900);--ui-color-typography-note:var(--ui-color-n-300);--ui-color-typography-button:var(--ui-color-n-000);--ui-typography-typeface:"Inter",sans-serif;--ui-typography-h1:1.9375rem;--ui-typography-h2:1.5625rem;--ui-typography-h3:1.25rem;--ui-typography-p:1rem;--ui-typography-s:.8125rem;--ui-typography-h1-leading:1.2;--ui-typography-h2-leading:1.2;--ui-typography-h3-leading:1.25;--ui-typography-p-leading:1.5;--ui-typography-margin-heading:.75rem;--ui-typography-margin-body:1.125rem;--ui-layout-container:1.25rem;--ui-layout-grid:3.625rem;--ui-layout-gutter:1rem;--ui-gap-cta:.75rem;--ui-gap-content:2rem;--ui-radius-button:5rem;--ui-radius-input:5rem}html{box-sizing:border-box}*,:after,:before{box-sizing:inherit}body{background-color:var(--ui-color-background-primary);color:var(--ui-color-typography-body);font-family:var(--ui-typography-typeface);font-feature-settings:"liga","kern";font-size:var(--ui-typography-p);font-weight:400;line-height:var(--ui-typography-p-leading);margin:0 auto;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased}a{color:var(--ui-color-brand);text-decoration:none}h1,h2,h3,p{margin-top:0}h1,h2,h3{color:var(--ui-color-typography-heading);margin-bottom:var(--ui-typography-margin-heading)}h1{font-size:var(--ui-typography-h1);line-height:var(--ui-typography-h1-leading)}h2{font-size:var(--ui-typography-h2);line-height:var(--ui-typography-h2-leading)}h3{font-size:var(--ui-typography-h3);line-height:var(--ui-typography-h3-leading)}p{margin-bottom:var(--ui-typography-margin-body)}p:last-child{margin-bottom:0}strong{font-weight:700}small{font-size:var(--ui-typography-s)}.ui-text-note{color:var(--ui-color-typography-note);line-height:1}img,svg{display:block;height:auto;margin:0 auto;max-width:100%}.ui-layout-container{padding-left:var(--ui-layout-container);padding-right:var(--ui-layout-container)}.ui-layout-flex,.ui-layout-grid{align-items:center;justify-content:center}.ui-layout-flex{display:flex}.ui-layout-grid{display:grid}.ui-component-cta{flex-direction:column;row-gap:var(--ui-gap-cta)}button,input{color:inherit;font-family:inherit;font-size:var(--ui-typography-p);line-height:1;margin:0;outline:0;text-rendering:inherit;text-transform:none}form{width:100%}.ui-component-form{background-color:var(--ui-color-form-input);border-radius:var(--ui-radius-input);grid-template-columns:minmax(0,1fr) auto;padding:.25rem}::placeholder{color:var(--ui-color-typography-note)}.ui-component-input{background-color:var(--ui-color-form-input);border:.0625rem solid var(--ui-color-form-input);border-radius:var(--ui-radius-input)}.ui-component-input-medium{height:2.5rem;padding:.625rem 1rem .75rem}button{background:0 0;border:0;cursor:pointer;display:block;padding:0}.ui-component-button{border:.0625rem solid var(--ui-color-brand);border-radius:var(--ui-radius-button);display:block;font-weight:700;line-height:1;text-align:center}.ui-component-button-primary{background-color:var(--ui-color-brand);color:var(--ui-color-typography-button)}.ui-component-button-medium{padding:.625rem .875rem .75rem;width:fit-content}.ui-section-header{padding-bottom:1.25rem;padding-top:1.25rem}.ui-section-header__layout{justify-content:space-between}.ui-section-content{padding-bottom:2em;padding-top:5rem;text-align:center}.ui-section-content--image{margin-bottom:var(--ui-gap-content);margin-top:var(--ui-gap-content)}.ui-section-content--feature{row-gap:var(--ui-gap-content)}.ui-section-content--icon{margin-bottom:1rem}.ui-section-close{padding-bottom:5rem;padding-top:5rem;text-align:center}.ui-section-footer{padding-bottom:1.25rem;padding-top:1.25rem}.ui-section-footer__layout{column-gap:var(--ui-layout-gutter)}.ui-section-footer--copyright{margin-bottom:0;margin-right:auto}@media screen and (min-width:48rem){:root{--ui-typography-h1:2.1875rem;--ui-typography-h2:1.75rem;--ui-typography-h3:1.4375rem;--ui-typography-p:1.125rem;--ui-typography-s:.875rem;--ui-typography-margin-body:1.25rem;--ui-layout-container:4.25rem;--ui-layout-gutter:1.5rem;--ui-gap-content:3rem}.ui-layout-column-center,.ui-layout-container{margin-left:auto;margin-right:auto}.ui-layout-grid-3{column-gap:var(--ui-layout-gutter);grid-template-columns:repeat(2,1fr);justify-items:center}.ui-layout-grid-3 div:last-of-type{left:calc(50% + (var(--ui-layout-gutter)/ 2));position:relative}.ui-layout-column-4{width:calc((var(--ui-layout-grid) * 4) + (var(--ui-layout-gutter) * 3))}.ui-layout-column-6{width:calc((var(--ui-layout-grid) * 6) + (var(--ui-layout-gutter) * 5))}.ui-section-header{padding-bottom:2rem;padding-top:2rem}.ui-section-content{padding-bottom:3rem}.ui-section-content--icon{height:4rem;width:4rem}.ui-section-footer{padding-bottom:2rem;padding-top:2rem}}@media screen and (min-width:64rem){:root{--ui-layout-container:0}a{transition:all 250ms ease}a:not(.ui-component-button):hover{color:var(--ui-color-typography-body)}.ui-layout-container{width:60rem}.ui-layout-grid-3{grid-template-columns:repeat(3,1fr)}.ui-layout-grid-3 div:last-of-type{position:static}}@media screen and (min-width:75rem){:root{--ui-typography-h1:2.75rem;--ui-typography-h2:2.1875rem;--ui-typography-h3:1.75rem;--ui-typography-h4:1.4375rem;--ui-typography-margin-heading:1rem;--ui-typography-margin-body:1.75rem;--ui-layout-grid:4rem;--ui-layout-gutter:2rem;--ui-gap-content:4rem}.ui-text-intro{font-size:var(--ui-typography-h4)}.ui-layout-container{width:70rem}.ui-section-header{padding-bottom:3rem;padding-top:3rem}.ui-section-content{padding-bottom:5rem;padding-top:7.5rem}.ui-section-content--icon{height:5rem;margin-bottom:1.125rem;width:5rem}.ui-section-close{padding-bottom:7.5rem;padding-top:7.5rem}.ui-section-footer{padding-bottom:3rem;padding-top:3rem}}:root{--material-color-yellow-50:#fffde7;--material-color-yellow-100:#fff9c4;--material-color-orange-500:#ff9800;--material-color-orange-600:#fb8c00;--base-background:#fff;--base-color:#333;--base-color-lighter:#777;--base-color-muted:#999;--yellow-background:var(--material-color-yellow-100);--yellow-background-lighter:var(--material-color-yellow-50);--orange-background-dark:var(--material-color-orange-500);--orange-background-dark-active:var(--material-color-orange-600);--hatena-color:#01a5df;--base-font:-apple-system,BlinkMacSystemFont,Helvetica Neue,Yu Gothic,YuGothic,Verdana,Meiryo,M+ 1p,sans-serif;--ui-gap-content:2em}.ui-text-note{color:var(--base-color-muted)}.ui-section-header__layout img{display:inline-block;width:24px;height:24px;vertical-align:middle}.ui-section-content{padding-top:2.5em;padding-bottom:3.5rem}.ui-section-header{padding-top:2rem;padding-bottom:1rem}.ui-component-form{border-radius:0;grid-template-columns:auto minmax(0,1fr) auto}.ui-component-form .ui-component-button{border-radius:0;background:var(--orange-background-dark);border-color:var(--orange-background-dark)}.ui-component-form .ui-component-button.active{background:var(--orange-background-dark-active);border-color:var(--orange-background-dark-active)}@media screen and (min-width:48rem){.ui-layout-grid-3 div:last-of-type{left:0}}@media screen and (min-width:75rem){.ui-layout-grid-3{grid-template-columns:repeat(4,1fr)}}.ui-typography-heading{text-align:left}.ui-typography-heading small{color:var(--base-color-muted)}img{color:var(--base-color-muted)}.ui-section-header__layout .ui-section-header__title{display:inline-block;line-height:22px;vertical-align:middle;font-weight:700;font-size:1.3em;color:var(--base-color)}.ui-top-section{padding-bottom:2em}.ui-component-form__label{margin-left:.2em}.ui-component-form__label img{width:32px;height:32px}.ui-component-form__label span{font-weight:700}.ui-top-section .ui-text-note{margin-bottom:.6em}.ui-top-section .ui-top-section__subscribe{margin-top:.3em;display:flex;gap:.5em}.ui-top-section .ui-top-section__subscribe img{height:37px;width:auto}.ui-section-nav__layout{justify-content:start}.ui-section-nav__link{font-weight:700;margin-right:1.5em;padding:.5em 0;border-bottom:2px solid transparent;color:var(--base-color-muted)}.ui-section-nav__link--active{color:var(--base-color);border-bottom-color:var(--base-color)}.ui-section-content__feed-date-heading{text-align:left;font-size:1.2em;color:var(--base-color-lighter);margin-top:1em;margin-bottom:1em;padding:.4em .3em;border-bottom:1px solid var(--base-color-lighter);position:sticky;top:0;z-index:1;background-color:var(--yellow-background-lighter)}.ui-section-feed{background:var(--yellow-background-lighter)}.ui-section-feed .ui-layout-grid{align-items:flex-start}.ui-section-feed .ui-text-note{text-align:left;font-size:.9em}.ui-container-feed{text-align:left;margin-top:1em;margin-bottom:2em;justify-items:left}.ui-container-feed.ui-container-feed--hot{margin-top:2em}.ui-feed-item{display:grid;color:var(--base-color);grid-template-columns:130px 1fr;align-content:start;grid-gap:0 0.5em}.ui-feed-item .ui-feed-item__og-image img{width:100%;height:auto;max-height:7em;object-fit:contain;object-position:center top}.ui-feed-item .ui-feed-item__title{font-weight:700;font-size:.9em;-webkit-line-clamp:3;-webkit-box-orient:vertical;display:-webkit-box;overflow:hidden;word-break:break-all}.ui-feed-item .ui-feed-item__title:hover{text-decoration:underline}.ui-feed-item .ui-feed-item__title:visited{color:var(--base-color-lighter)}.ui-feed-item .ui-feed-item__hatena-count{margin:.1em 0;font-size:.7em}.ui-feed-item .ui-feed-item__hatena-count img{display:inline;width:1.25em;height:1.25em;vertical-align:middle}.ui-feed-item .ui-feed-item__hatena-count span{color:var(--hatena-color);font-weight:700;vertical-align:middle}.ui-feed-item .ui-feed-item__blog-title{margin:.3em 0;font-size:.75em}.ui-feed-item .ui-feed-item__blog-title--link:hover{text-decoration:underline}.ui-feed-item .ui-feed-item__summary{font-size:.75em;margin:.3em 0;word-break:break-all;overflow:hidden;-webkit-line-clamp:2;-webkit-box-orient:vertical;display:-webkit-box;color:var(--base-color-muted)}.ui-feed-item .ui-feed-item__date{color:var(--base-color-muted);font-size:.7em}@media screen and (min-width:48rem){.ui-feed-item{display:block}.ui-feed-item .ui-feed-item__og-image{display:block}.ui-feed-item .ui-feed-item__og-image img{height:9em;max-height:9em}.ui-feed-item .ui-feed-item__title{margin-top:.5em}}@media screen and (min-width:75rem){.ui-feed-item .ui-feed-item__og-image img{height:8em;max-height:8em}}.ui-section-blog{background:var(--yellow-background-lighter)}.ui-container-blog{text-align:left;margin-top:2em}.ui-blog{display:grid;color:var(--base-color);grid-template-columns:130px 1fr;align-content:start;grid-gap:0 0.5em}.ui-blog .ui-blog__og-image img{width:100%;height:auto;max-height:7em;object-fit:contain;object-position:center top}.ui-blog .ui-blog__title{display:block;font-weight:700;word-break:break-all}.ui-blog .ui-blog__title:hover{text-decoration:underline}.ui-blog .ui-blog__link{display:block;font-size:.7em;word-break:break-all;overflow:hidden;margin:.2em 0}.ui-blog .ui-blog__link:hover{text-decoration:underline}.ui-blog .ui-blog__description{font-size:.75em;margin:.3em 0;word-break:break-all;overflow:hidden;-webkit-line-clamp:2;-webkit-box-orient:vertical;display:-webkit-box;color:var(--base-color-muted)}.ui-blog .ui-blog__date{color:var(--base-color-muted);font-size:.7em}@media screen and (min-width:48rem){.ui-blog{display:block}.ui-blog .ui-blog__og-image{display:block}.ui-blog .ui-blog__og-image img{width:auto;height:9em;max-height:9em}.ui-blog .ui-blog__title{margin-top:.5em}}@media screen and (min-width:75rem){.ui-blog .ui-blog__og-image img{width:auto;height:8em;max-height:8em}}.ui-container-blog-summary{text-align:left;margin-bottom:2em}.ui-blog-summary .ui-blog-summary__link{display:block;word-break:break-all;overflow:hidden;margin:.2em 0}.ui-blog-summary .ui-blog-summary__link:hover{text-decoration:underline}.ui-blog-summary .ui-blog-summary__description{margin:.3em 0;word-break:break-all;color:var(--base-color-muted)}
</style><script async src="https://www.googletagmanager.com/gtag/js?id=G-CNNNTL0NB3"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-CNNNTL0NB3")</script><title>Stockmark Tech Blogのフィード｜企業テックブログRSS</title></head><body><header role="banner" class="ui-section-header"><div class="ui-layout-container"><div class="ui-section-header__layout ui-layout-flex"><a href="https://yamadashy.github.io/tech-blog-rss-feed/" role="link" aria-label="#"><img src="../../images/icon.png" alt="サイトロゴ" loading="lazy" decoding="async" width="96" height="96"> <span class="ui-section-header__title">企業テックブログRSS</span> </a><a href="https://github.com/yamadashy/tech-blog-rss-feed/" role="link" aria-label="#"><img src="../../images/github-mark.png" alt="GitHubロゴ" loading="lazy" decoding="async" width="96" height="96"></a></div></div></header><main role="main"><nav class="ui-nav"><div class="ui-layout-container"><div 
class="ui-section-nav__layout ui-layout-flex"><a class="ui-section-nav__link" href="../../">フィード</a> <a class="ui-section-nav__link" href="../../hot/">人気フィード</a> <a class="ui-section-nav__link" href="../../blogs/">ブログ一覧</a></div></div></nav><section class="ui-section-content ui-section-feed"><div class="ui-layout-container"><h2 class="ui-typography-heading">Stockmark Tech Blog</h2><div class="ui-container-blog-summary"><div class="ui-blog-summary"><a class="ui-blog-summary__link" href="https://tech.stockmark.co.jp/">https://tech.stockmark.co.jp/</a><p class="ui-blog-summary__description">自然言語処理テクノロジーで社会を進化させるストックマークのテックブログです。</p></div></div><h3 class="ui-typography-heading">フィード</h3><div class="ui-section-content--feature ui-layout-grid ui-layout-grid-3 ui-container-feed ui-container-feed--no-image"><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/branching_strategy/"><picture><source type="image/webp" 
srcset="../../images/feed-thumbnails/3VC7A-i5yo-150.webp 150w, ../../images/feed-thumbnails/3VC7A-i5yo-450.webp 450w" sizes="100vw"><source type="image/jpeg" srcset="../../images/feed-thumbnails/3VC7A-i5yo-150.jpeg 150w, ../../images/feed-thumbnails/3VC7A-i5yo-450.jpeg 450w" sizes="100vw"><img alt="記事のアイキャッチ画像" loading="lazy" decoding="async" src="../../images/feed-thumbnails/3VC7A-i5yo-150.jpeg" width="450" height="248"></picture></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/branching_strategy/">開発チームのスケールに向けたブランチ戦略見直し</a><div class="ui-feed-item__hatena-count" title="はてなブックマーク数"><img src="../../images/hatenabookmark-icon.png" alt="はてなブックマークアイコン" loading="lazy" decoding="async" width="96" height="96"> <span>7</span></div><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
概要 組織の拡大に伴う開発チームの分割、独立性向上のためにGitHubの運用フロー見直しと同時にFeature Flagの導入を行いました。 結果として、独立した開発をしてもコンフリクトが発生しづらくなったことにより生産性が向上、副次的効果として部分リリースにより問題の先行発見をしやすくなり、品質向上にもつながりました。 背景：GitHubのブランチ戦略がチームスケールの弊害に プロダクトや会社の成長に伴い、開発チームにはスピードと安定性の両面が求められるようになっていきますが、少人数のメンバーだと限界がやってきます。実際に、小さな改善はできるけど、ソフトウェアアーキテクチャ自体を見直すような大きな改善施策は、新規開発もある中で中々優先度を上げられないような状態が起きていました。 このような状況下で、開発組織としては総スループットを向上させる必要がありますが、単純に同じプロダクトの開発人数を増やしていくと、調整コストの増大、コンフリクトの発生などにより生産性が思うように上がりません。Anews開発チームでは３人の小さなチームに分割して独立性を高め調整コストを下げる方針をとりましたが、時に大きなコンフリクが発生してしまい、これを防ごうとすると調整コストが発生する状況にあり、両立が課題になっていました。 変更前の運用：コンフリクトと調整コストのトレードオフ 運用方法 開発項目毎にmasterからfeatureブランチを派生する １開発が大きい場合、サブタスク用のブランチをfeatureブランチから派生する（図中feature/greenの例） 開発項目毎に、サブタスク全てが完了してからdevelopment環境にリリースし受け入れレビューを行う リリースは毎週実施しており、火曜日に受け入れレビューが完了している全てのfeatureブランチをreleaseブランチにマージし、staging環境にリリースしてテスト 木曜日にstagingブランチをmasterブランチにマージし、production環境にリリース 発生していた課題 規模の大きな開発の場合、コード変更がベースブランチであるmasterにマージされるまでの期間／規模が大きくなり、大きなコンフリクトが発生するリスクが高い（図中feature/greenとfeature/redをrelease/2にマージするタイミ...
</div><div class="ui-feed-item__date" title="2022-06-22 02:00:00">9日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/stockmark_data_team_evolution/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/stockmark_data_team_evolution/">個別最適でプロダクトを作り続けたスタートアップがデータ専任部隊を作ることにした話</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
2022/5/25 に Stockmark Tech Meetup #02 を開催しました！本記事では、2つ目のLTである “個別最適でプロダクトを作り続けたスタートアップがデータ専任部隊を作ることにした話” を再編成してお伝えいたします。本記事を読むことで、以下の2点が分かります。 AIスタートアップが膨大なデータに立ち向かってきた歴史 ストックマークが抱える膨大なデータに対して、どのように開発チームがアプローチしているか ストックマークのプロダクトはデータに支えられている まず前提として、ストックマークのプロダクトである Anews と Astrategy はどちらも、国内外で公開されている膨大なデータを利用しています。 AnewsとAstrategyは膨大なデータに支えられている 上図のデータはWebクローラーによって毎日収集され蓄積されています。実装としては、大量のAWS lambdaによる汎用的な収集・抽出処理が内部で動作しています。Webクローラーときくと、「え、データを取ってくるだけでしょ？」と思われるかもしれませんが、そんなに単純ではなく非常に厄介な問題があります。 「何もしてないのに壊れる」のではなく「何もしてないと壊れる」 Webというのは常に動的に変化するものです。Webクローリングを実施する場合、ある程度のHTML構造をベースにデータを抽出していきます。たとえば、このタグのここには必要となる情報が存在している、このタグは不要な情報である、といったように判断しながら情報を収集しているということです。 HTML構造が変化しなければ問題ないのですが、Webは常に進化していきます。したがって、更新に追従し続けなければ、クローリングの失敗数が漸進的に増えてしまうのです。結果として、データに支えられるはずのプロダクトの価値が低下することになります。 Phase0: どちらのプロダクトが対応する？ 歴史的に、Anews と Astrategy の2つのプロダクトはコアな価値探索にフォーカスするため、別にチームで開発されてきました。Webクローラーの開発は、下図のとおりでプロダクト間の隙間に落ちているような状態になっていました。 開発体制 Phase0 Phase1: 役割の一部を明確化 ここで、まず取り組んだのはそれぞれのチームの適任メンバー数人が掛け持ち...
</div><div class="ui-feed-item__date" title="2022-06-12 23:30:00">18日前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/multilingual-language-models/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/multilingual-language-models/">日本語ニュース分類から見る多言語モデル</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
グローバル化が進む現代において、様々な言語で情報収集を行う必要性がこれまで以上に高まっています。Stockmark ではそうしたお客様の情報収集を支援するために多言語テキストの解析にまつわる研究が行われています。本日はその基礎技術である多言語モデルについて紹介します。 多言語モデル (multilingual language models, crosslingual language models) は複数の言語を扱うことができる言語モデルです1。リソースが十分にない言語での下流タスクにおいて、多言語モデルのパフォーマンスが単言語の言語モデルよりも優れていることが報告されています (Wu and Dredze 2019)。また多言語を1つのモデルで扱えるようになることで、言語ごとに異なるモデルを用意する必要がなくなるという運用上の利点もあります。こうした点から近年では多言語モデルは自然言語処理の研究における1つのホットトピックになっており、Hugging Face 上で mulitiilngual タグがついたモデルは 2022年4月現在 320 を超える盛り上がりを見せています。 一方で日本語のような英語と文法的に大きく異なる言語では多言語モデルの性能が低いことも報告されています (Pires+ 2019)。そこで本記事では英語と日本語に着目し、ニュース記事タイトルのラベル分類を例にとって多言語モデルの性能を検証します。 ニュースタイトル分類タスクでの実験 本記事では日本語のニュース記事のラベル分類を例に取り、次の2つの fine-tuning の方法を比較します。 日本語のニュース記事分類データでのみ fine-tuning を行う 英語のニュース記事分類データで事前に fine-tuning を行ってから日本語データで fine-tuning を行う 両者の違いは、日本語データでの fine-tuning の前に英語データでの fine-tuning を行うかどうかという点にあります。一般に英語のデータは日本語のデータに比べ多く手に入れやすいため、後者でより精度が高くなる場合はモデルの改善を行う上で大きな利点があります。 データセット 本実験では英語の記事ラベルデータセットとして News Article Classification dataset (NA...
</div><div class="ui-feed-item__date" title="2022-05-02 03:00:00">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/similar_articles_ja/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/similar_articles_ja/">検索エンジンのMore-Like-Thisクエリとグラフアルゴリズムによる類似記事集約</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
本記事は Grouping Similar Articles with Search Engine More-Like-This Queries and Graph Algorithms の翻訳記事です。以前の記事である More Like This Query を活用した類似記事集約 入門 から、より踏み込んだ内容になっています。 はじめに ストックマークでは、毎日数千のメディアから数万件のニュース記事を収集しています。そのときに、異なるメディアから類似した内容の記事がクロールされることもあります。その一方で、これらの内容の重複した記事をそのままユーザに表示してしまうと、ユーザの情報収集体験を損ねてしまう可能性があります。そのため、ストックマークのプロダクトであるAnewsので記事推薦や、Astrategyでの事業活動比較などのニュース分析サービスにおいて、より良いユーザー体験を提供するためには、類似記事を検出して集約するのが重要です。 全く同じ内容の記事を集約するのは比較的簡単です。難しいのは、同じ内容の記事ですが、表現のやや異なる記事も集約する必要がある点です。類似記事の多くは、同じ文章を複製しているのではなく、同じ記事を別の著者が書いたという形になっています。 ストックマークでは、文書の類似性を見つけるために検索エンジンを利用しています。また、類似した記事をグループ化するためにグラフアルゴリズムを利用しています。以降で、詳細は説明していきましょう。 類似性グラフの構築 記事を集約する前に、類似性グラフを最初に構築します。グラフの各ノードは記事を表しており、2つのノードが類似していると判断された場合、2つのノード間にエッジが存在しています。類似性定義のためのメトリックによって、グラフは有向もしくは無向になります。今回の場合は有向グラフになります。 記事が固定次元のベクトルで表現できれば、doc2vec や S-BERT を利用して、ベクトル距離を計算して記事の類似性を計算できます。今回のプロジェクトでは、これとは異なる方法を利用しています。すなわち、記事の類似性取得に全文検索エンジンを利用しています。実際に、全文検索エンジンを利用したアプローチの方が、高精度で柔軟な検索が可能であることがわかりました。 ストックマークでは、ニュース記事のインデクシングに Ela...
</div><div class="ui-feed-item__date" title="2022-04-27 03:00:00">2ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/similar_articles/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/similar_articles/">Grouping Similar Articles with Search Engine More-Like-This Queries and Graph Algorithms</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
Please refer here for a related post in Japanese. Introduction In Stockmark, we collect tens of thousands of news articles from thousands of different media sources every day. Articles with similar content may be crawled from different news media. It is vital to detect and group similar articles in order to provide better user experience by improving our news analytics services, such as Anews recommendations, Astrategy business activity comparisons, etc.</div><div class="ui-feed-item__date" title="2022-04-14 10:42:55">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/more_like_this_opensearch/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/more_like_this_opensearch/">More Like This Query を活用した類似記事集約 入門</a><div 
class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
はじめに 本記事では、ストックマークのプロダクトの実装で工夫している類似記事集約という技術について紹介します。本技術により、多くのドキュメントを扱う機会がある場合に、お客様に高い価値を提供できるようになります。 ストックマークでは社内のResearchチームと連携して、類似記事集約において実装面での工夫をいくつか積み重ねています。本記事ではまずイントロダクションとして、特にコアとなる OpenSearch の More Like This Query について紹介します。今後公開する別記事では、さらに発展的な類似記事集約の仕組みを紹介予定です。 さて、本記事で扱う主なトピックはこちらです。 類似記事集約がなぜ必要なのか？ 類似記事集約の実装方法とロジック ストックマーク独自の工夫 過去記事を含む再適用 というわけで早速、本題に進みましょう！ 類似記事集約がなぜ必要なのか？ ストックマークのプロダクトは、世の中で大量に生成されるニュース記事を情報源として活用しています。ニュース記事は、各種メディアサイトに掲載されるため、ほとんど同一の内容が同日の記事として載ることがあります。たとえば、次の図では自社のプレスリリースが複数メディアで取り上げられており、全て同一記事であると判定している例です。 Astrategyにおける記事集約イメージ 仮に何の工夫もしないナイーブな状態で、ニュース記事をお客様に見せてしまうと、内容の重複する記事ばかりになってしまいます。そこで、類似の記事はまとめておいて、お客様には1つの記事を返すことでUXを向上できます。 どうやって実装しているのか？ 類似記事集約は、技術的には一種の文書クラスタリングであり、様々な実装方法があります。 ストックマークでは類似記事集約実装のために、Amazon OpenSearch Service (以下、OpenSearch) を利用しています。OpenSearchは、Elasticsearch からフォークされており、Elasticsearchの More Like This Query の機能を活用できます。今回の類似記事集約では、まさにこの機能を実現方法の一部として活用しています。 More Like This Query のロジック そもそも、ある文書Aと文書Bが同一であること(似ていること)をどのように判断...
</div><div class="ui-feed-item__date" title="2022-04-10 23:00:00">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/denshosen2021/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/denshosen2021/">ボケて電笑戦への挑戦〜AIで画像大喜利〜</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
こんにちは、Machine Learning部門の森長です。 昨年(2021年)の9月に開催されました、AWS Dev Day Online Japanのスペシャルプログラム #1：ボケて電笑戦に参加させていただきました。 そこで、本記事では、ボケて電笑戦で作成したお笑いモデルについて紹介いたします。 ボケて電笑戦とは ボケて電笑戦とは、「AIは人を笑わせられるのか？」という問いを解明すべく、アマゾンの奥地へ向かった膨大なボケのデータを学習させて新たな笑いを作り出せるのかを競い合う挑戦です。 今回のボケて電笑戦では、弊社を含め3企業がお笑いモデルを独自に作成して、人を笑わせるべく大喜利対決を行いました。 詳細は、スペシャルプログラム #1：ボケて電笑戦に以下のような記載されていますので、ご覧いただければと思います。 人間の喜怒哀楽に AI は影響を与えることができるのでしょうか。「ボケて電笑戦」はその命題に挑戦した AI 大喜利対決です。 国内最大級のお笑いメディア『ボケて』の約 100 万のお笑いのデータを利用して、人間が考え出したボケを上回る新たな笑いをAI が作り出せるのかを競い合う『ボケて電笑戦』。まさに新時代の笑いをテクノロジーで切り開くかもしれない壮大なチャレンジです。ぜひお見逃しなく！ 上記の本戦の様子は公開されておりませんが、テクニカルセッションが公開されています。 また、2020年に参加企業を含めた紹介記事(2020年当時のお笑いモデルの紹介)が以下にて公開されています。 ボケて電笑戦記事の1つ目 ボケて電笑戦記事の2つ目 ボケて電笑戦記事の3つ目 では、以降からこのボケて電笑戦で弊社が作成したお笑いモデルについて紹介していきます。 お笑いモデルの構築 まず、ボケの教師データとして、お笑いメディア『ボケて』の約100万のお笑いデータ(画像とその画像のボケテキスト)をご提供いただきましたので、教師あり学習でお笑いモデルを構築することにしました。 お笑いモデルの構築の流れはおおまかに分類すると以下の手順になります。基本的にはこの手順を何度も繰り返し、お笑いモデルをブラッシュアップしていきます。 教師データの準備 教師データの前処理 お笑いモデルの構成と学習 生成したボケの後処理 生成したボケの評価 では、最終的なお笑いモデルがどのように作成されたかを上...
</div><div class="ui-feed-item__date" title="2022-03-18 03:00:00">3ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/mobile-app-architecture-20211221/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/mobile-app-architecture-20211221/">開発速度向上のためのAnewsモバイルアプリのアーキテクチャ改善</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
はじめに こんにちは、Anewsのエンジニアリングマネージャーの山崎です。 この記事はストックマークアドベントカレンダーの22日目の記事です。 普段は、エンジニアリングマネージャーとして開発体制や中長期のエンジニア戦略を考えています。 またエンジニアリングマネージャーとは別にエンジニアとしてAnewsのFlutterアプリの開発を行なっています。 Anewsの開発組織では全員がフルスタックエンジニアとして働くことを推奨しており、 開発体制やプロセスについてもフロントエンド、バックエンドなどの領域を意識せず顧客への価値提供を最大化するためエンジニアが必要な開発を行うようにしています。 その中で、モバイルアプリだけは固定されたメンバーで開発を行うような体制になっています。 理由としては、 ・ モバイルアプリの開発経験が少ない ・ モバイルアプリのコードが複雑になっており、学習コストが高くなっている この問題を解決するために未経験者でも開発が行いやすいようにするため、モバイルアプリのアーキテクチャを見直すことにしました。 今回は現在行なっているアーキテクチャ刷新の全体像を紹介できればと思います。 現在の問題点 現在のアーキテクチャ問題点について ・開発ルールがないため個々のエンジニアの裁量で設計が決まっていく ・コード全体で依存関係が整理されておらず処理を追うことが難しい ・コードの結合度が高くコード改修での影響範囲が広くなる この問題を解決するためにレイヤードアーキテクチャを採用し、階層ごとに処理を分割しUI部分についてはAtomic Designのコンポーネント分割を参考に分割することで影響範囲や処理のルールがわかりやすいようにしています。 全体のアーキテクチャの方針 UI, Domain, Infrastructureの３層構造にすることにより、依存関係を整理し影響範囲をわかりやすくしました。 UI：表示処理を行うコンポーネント Domain：UIとは切り離されたビジネスロジックの集合 Infrastructure: 外部リソースとの接続処理の集合 ディレクトリ構成もレイヤーにより分割することにより、ディレクトリ内に含まれているコードの予想ができ探しているコードを見つけやすい状態にしています。 Domain, Infrastructureの方針 DomainとInf...
</div><div class="ui-feed-item__date" title="2021-12-22 08:00:00">6ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/20211120_mind_discovery/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/20211120_mind_discovery/">Anewsへの応用を見越した既存ニュース推薦手法の性能確認実験</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
ML事業部の金田です。今回はAnewsへの応用を見越して実施した、公開データセット（MINDデータセット）を用いた既存ニュース推薦手法の性能確認実験について紹介します。なお、実験で用いたコードはこちらに公開しています。 背景 当社の開発する法人向けサービスのAnewsには、ニュース推薦システムが実装されています（その概要は以前の記事で紹介したとおりです）。 このシステムは、製品開発の初期段階に構築されたものです。その際には顧客要求を素早く叶えることが優先されており、当時はニュース推薦システムの研究動向を十全にフォローアップできていませんでした。構築以降に実施されたシステム品質改善も、顧客から寄せられた問題の解消を目的としていたため、「そもそも技術的観点から現行システムにどの程度改善の余地があるのか？」という疑問に対して、これまで明確な回答を用意できていませんでした。 この問題を解消するため、現在R&amp;Dユニットでは、製品で必要とされる機能プロトタイピング/機能改善の傍ら、ニュース推薦モデルに関する論文調査・社内データへの適用性確認（現行アルゴリズムとの比較評価）を試みています。このたび紹介する内容は、この調査の過程で生まれた、公開データセット（MINDデータセット）を用いた既存提案手法の性能確認結果になります。 MINDデータセット MINDデータセット1 2は2020年にMicrosoft社の公開した、ニュース推薦のためのデータセットです。このデータセットはMSNニュース（英語）の利用ログから構築されたもので、次のデータを含んでいます。 行動データ（behavior.tsv） あるクリック履歴（history）を持つユーザが行った、あるタイミングで提示されたニュースリストに対する反応（impressions）。データの概観は下図のとおりです。 図1. 行動データの概観 ニュース記事データ（news.tsv） 行動データに含まれるニュース記事の情報。各記事は以下の属性を持ちます。 記事ID タイトル アブストラクト 本文3 カテゴリ サブカテゴリ MINDデータセットには上記以外にもデータ/ニュース記事属性が含まれていますが、ここでは以降の実験に関係するものに絞って紹介しています。 （全容及び詳細に興味のある方は公式の説明をご確認ください）。 このデータセットで扱う問...
</div><div class="ui-feed-item__date" title="2021-12-08 03:00:00">7ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/how-we-accelerate-development/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/how-we-accelerate-development/">自由と責任を開発チームにもたらしたら開発速度が上がった話</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
ストックマークの開発体制は、プロダクトの成長フェーズに合わせて、2021年夏に大きく進化しています。本エントリでは、何が課題でどう進化したのか？を紹介いたします。本エントリを読むことで、スタートアップの開発体制で発生する課題と、その解決方法の1つを理解できます。 サマリ 開発チームのパフォーマンスが最大化できていなかった 開発チームに自由と責任を委譲し、より自律的な行動を促進した スクラムを辞めて、カンバンを主軸とする開発へ その結果、開発スピードが大きく向上し、より迅速にアウトカムを提供できるように どんな課題が存在していたのか？ 大きく分けて、開発チームに関する2つの課題が存在していました。 課題1: リソースの偏り ストックマークの以前の開発体制(〜2021年8月)では、Anewsの開発チームは大きく分けて、 以下の2つが存在していました。 情報収集機能を開発するチーム コミュニケーション機能を開発するチーム それぞれのチームが、常にパフォーマンスを最大化できていれば良いのですが、実際には片方のチームがビジーであり、もう片方のチームの負荷が軽い時期がある、などの状態が発生していました。 また、Slackなどで情報同期・可視化はしているものの、一部の仕事が重複しているケースもありました。 課題2: 余剰リソースが一時浮き 新しい価値を開発をすすめる場合に、プロダクトマネージャが主導権を握っており、開発チームが自律的に新価値開発を実施できていないケースがありました。 もちろん、機能の内容や優先度はプロダクトマネージャが責務を担っている点は自然ですが、プロダクトマネージャとの調整をしないと、一時的にリソースが浮くケースがあったのです。 Anewsというプロダクトは急速に成長を遂げている真っ只中であり、新価値を高速に提供するのが重要なフェーズです。そのため、ここまで述べた2つの課題は早急に解決する必要がありました。 どのような解決方法をとったのか？ 課題2冒頭で述べた、主導権を開発チームに移しました。言葉だけだとわかりにくいので、Before/Afteを簡易Value Stream Mapで説明します。 簡易Value Stream MapでのBefore/After 最大の違いは、Push型のフローから、Pull型のフローに変更したという点です。すなわち Befor...
</div><div class="ui-feed-item__date" title="2021-10-18 03:00:00">8ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/vue2_performance_with_bigdata/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/vue2_performance_with_bigdata/">Vue 2で大きなデータを扱うときの性能改善手法</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
本エントリは2021年8月30日に開催されたNode学園 37時限目 オンラインにて、「Vue 2で大きなデータを扱うときの性能改善手法」というタイトルで発表させていただいた内容をテックブログ記事化したものです。発表当日の様子はYouTubeにアーカイブで公開されておりますので、そちらも合わせてご覧いただけましたら幸いです。 はじめに ストックマークでは、法人ユーザー向けに「Astrategy」というウェブサービスを開発・提供しています。Astartegyの詳細や技術的な全体構成についてはAstrategyを支える技術: gRPC, Elasticsearch, Cloud TPU, Fargate… SaaS型AIサービスの内側の世界というエントリで紹介しておりますのでそちらを参照いただくとして、本エントリではAstrategyのフロントエンドを構築する上で重要である性能改善手法について紹介したいと思います。 Astartegyでは大きなテーブルとして可視化されたデータをインタラクティブに操作する部分があり(図1)、そのため、大きなデータを一括で取得しフロントエンドで可視化するといったことをしています。ここの設計の是非については議論の余地がある部分かとも思いますが、本エントリではそこは一旦置いておき、1MB前後のJSONがバックエンドから返され、それを高速に取り扱う必要がある場面で、いかに性能改善するかをお伝えします。 図1: ドラッグ &amp; ドロップでインタラクティブにデータを可視化 Astrategyで取り組んだ性能改善 前提として、本エントリのタイトルにもあるとおり、AstrategyではVue 2をフロントエンド構築のためのフレームワークとして採用しています(Vue 3への移行は絶賛準備中です)。また、一口に性能と言っても様々な切り口がありますが、本エントリにおいては大きいデータを取り回してインタラクティブなコンテンツを作るということで、いわゆるランタイム性能の話に着目します。 そして、Astrategyの開発においても「推測するな、計測せよ」の鉄則に従い、Chrome DevToolsでプロファイリングしてボトルネックを見つける、そのボトルネックを改善する、さらに計測する、といったことを何度も繰り返しています。なお、DevToolsの使い方そのものについて...
</div><div class="ui-feed-item__date" title="2021-10-01 03:00:00">9ヶ月前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/gpu_translate/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/gpu_translate/">AWSを活用した機械翻訳のためのGPU並列処理環境の構築</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
はじめに こんにちは、ストックマークでエンジニアをしている麻生です。ストックマークでは、「Anews」というウェブサービスを提供しています。この度、Anewsで新機能導入のために日次バッチの大規模なインフラ変更を行い、GPU並列処理環境を構築しましたのでご紹介します。 組織の自律化を支援するナレッジプラットフォーム「Anews」 Anewsは国内外30,000メディアのニュースを毎日収集し、最先端の自然言語処理で個人や組織のミッションに即したニュースをレコメンドします。コメント機能で簡単にチームにアイデアを共有でき、社内の知見者から学ぶことでチームの情報感度が底上げされます。 エンタープライズを中心に、累計1500社以上のお客様にご利用いただいているサービスです。 Anewsのプロダクトイメージ 英語記事をレコメンドする上での課題 Anewsでは、記事への行動履歴からユーザーや組織の好みを学習し、記事をレコメンドしています。ユーザーが記事に対してシェアやコメントをするほど行動履歴が蓄積され、記事のレコメンド精度が向上する仕組みです。 レコメンドについてはこちらの記事に詳しい解説があります。 アクションを取らなければ記事のレコメンド精度の向上が見込めないのですが、そこで問題になるのが英語記事です。日本語を母国語とする以上、英語記事を読むのは負荷のかかる作業で、どうしても記事へのアクションが少なくなってしまいます。そのため、英語記事のレコメンド精度は上がりにくく、精度が低いことでレコメンドに繋がる行動履歴も蓄積されない、という悪循環に陥っていました。 お客様によっては海外の情報が重要なケースもあり、英語記事のレコメンド精度をいかに上げるかが課題でした。 日本語記事への行動履歴活用によるレコメンド精度向上 そこで今回持ち上がったのが、日本語記事への行動履歴を元に、英語記事をレコメンドするというアイデアです。英語記事を読まないユーザーも日本語記事への行動履歴は蓄積されているため、それが使えれば英語記事のレコメンド精度を向上させられるはずです。 単純なアイデアですが、英語と日本語では文章の性質が全く異なるため、日本語記事への行動履歴をそのまま英語記事に活用できません。一度、日本語記事を英語記事に翻訳することで、あたかも英語記事へのアクションがあったかのようなデータを作成する必...
</div><div class="ui-feed-item__date" title="2021-06-15 02:30:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/20210601_anews_recommendation/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/20210601_anews_recommendation/">Anewsの裏側で動く、自然言語処理を活用したビジネスニュースの推薦システム</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
ML事業部の金田です。今回は、ストックマークの提供する法人向けサービス「Anews」の裏側で動くビジネスニュース推薦システムについて、簡単に紹介いたします。 Anewsとは Anewsは組織変革のための情報収集＋コミュニケーションプラットフォームです。 情報収集のためのコア機能としては、国内外３万メディアから収集したビジネスニュースから、利用者の興味・関心に合わせて記事を配信するサービスを提供しています。日々配信されるニュースから業務ニーズに直結するインサイトを獲得し、これを話題にユーザ同士が交流することで、組織全体の情報感度やコミュニケーションを促進させるのが、サービスの狙いです。 Anewsのプロダクトイメージ 事前準備：ことばの定義 具体的な機能説明の前に、Anewsにおける基本的な概念について軽く整理します。 Anewsは1企業＝1集団としての利用を想定しています。以降ではこの集団をチーム、チームに所属する各利用者をメンバーと呼ぶことにします。ニュース配信の際に利用する情報は、基本的にチーム毎に独立しています。 各チームでは、特定の話題を追うためのチャンネルであるテーマを作成することができます。テーマに存在するテーマフィードには、設定されたキーワードにマッチするようなニュースリストが一日一回配信されます。 キーワード設定画面 テーマ画面。「関連ニュース」及び「新着ニュース」がテーマフィードに相当 一般に、レコメンデーションシステムではコールドスタート問題の解消が課題とされます。これは、サービスを初めて利用するユーザに発生してしまう、次のような問題です。 初利用するユーザからは興味・関心を表す手がかりが得られないため、よいレコメンドが行えない よいレコメンドが行われないため、ユーザが自身の興味・関心を提示する前に離脱してしまう テーマフィードでは初期設定時のキーワードを手がかりとすることで、この問題に対処しています。 メンバーはフィード上のニュースに対し、自由に閲覧、マーク、コメントといった行動をとることができます。これらの行動は、より良いニュースを配信するための手がかりとして利用されます。テーマフィードに配信されるニュースリストはメンバーに依らず同一であるため、これを共通の話題として扱うことができます。 行動履歴が一定以上蓄積したメンバーに対しては、一人ひと...
</div><div class="ui-feed-item__date" title="2021-06-07 03:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/astrategy_overview/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/astrategy_overview/">Astrategyを支える技術: gRPC, Elasticsearch, Cloud TPU, Fargate... SaaS型AIサービスの内側の世界</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
ストックマークでは、法人ユーザー向けの「Astrategy」というウェブサービスを開発、提供しています。 本エントリでは、Astrategyで使われている技術やシステム構成をご紹介したいと思います。 Astrategyとは Astrategyとは、AIがウェブニュースを解析してあらゆる市場の動向やトレンド、有力企業の経済活動を可視化し、ユーザーが市場調査や市場分析レポート作成を行うことができるウェブサービスです。 国内外約3万メディアから配信された約5000万件のビジネスニュースから、企業情報、言及されているニューストピック、業界や地域属性を抽出して分析に利用します。 抽出には汎用言語モデルBERTを用いており、その処理はCloud TPU上で動く重たい処理であるため、事前に全てのニュースデータに対して抽出処理をかけた状態で検索サーバーに登録しています。 ユーザーがAstrategyにアクセスし、欲しい記事の条件を入力すると、検索サーバーからその条件に合う記事を一度に取得し、そこにどのようなテーマが含まれているか、どのようなプレイヤー(企業、団体など)が存在するかなどを複数の切り口でインタラクティブに可視化します(図1)。 さらに、検索・分析の過程を保存する「ワークシート」と呼ばれる機能により、検索から分析の試行錯誤や定点観測をサポートしています。 図1: 「自然言語処理」についてテーマ x 企業で分析している様子 高速なデータ構造化とリアルタイム分析を行うアーキテクチャ アーキテクチャの全体像は図2のようになっており、AWSとGCPを利用しています。 図2: Astrategyのアーキテクチャ 記事検索機能にはElasticsearchを用いており、そこにアクセスする部分のほとんどがPythonで書かれたマイクロサービス（AWS Fargate）となっています。 フロントエンドと各マイクロサービスとの間にはRailsをAPIサーバとして配置し、BFF(Backend for Frontend)のような扱いで利用しています。 それによって、各マイクロサービスとRailsはgRPCによって高速に通信しつつ、フロントエンド向けにデータを加工して返しています。 もう一台あるElasticsearchは、検索キーワード等の自動補完用です。 マイクロサービス（Fargate）...
</div><div class="ui-feed-item__date" title="2021-05-09 15:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/gpt2_ja/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/gpt2_ja/">GPT-2におけるテキスト生成</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
はじめに Machine Learning部門の江間見です。ストックマークでは、自然言語処理技術の研究開発を行っています。 昨今、OpenAIからGPT-3が発表され、生成系モデルが大きな注目を集めています。 そこで、本記事では、弊社で作成している生成系モデルの紹介をいたします。 自然言語処理におけるテキスト生成 自然言語処理（NLP）は、人間の言語（自然言語）とコンピュータの相互理解、特に大量の自然言語データをコンピュータに処理および分析させるための研究分野です。 今回紹介するテキスト生成は、この自然言語処理の研究分野の一つです。 テキスト生成の応用例の一つは、スマートフォンのキーボードでの次の単語の予測です。このタスクはまさに​​言語モデルが行うことと同様です。言語モデルは、単語のリストを受け取り、次の単語を予測します。 図1の例では、言語モデルが「今日は」という単語を受け取り、次の単語である可能性の単語リストを返すシステムと考えることができます（図では、「良い」が最も可能性が高い単語です）。 図1. スマートフォンでの次単語予測の一例 テキスト生成モデルは、基本的に次の単語の予測を自動的に繰り返してテキストを生成する言語モデルです。 テキスト生成モデルにも多種多様なモデルがありますが、本記事では、OpenAIから発表されました「GPT-2」を取り扱います。 GPT-2とは 2019年2月にOpenAIからGPT-2が発表されました。 本モデルは、発表時にOpenAIの開発陣から「あまりにも高度な文章が作成でき、危険過ぎる」と危惧されGPT-2の論文公開が延期され、また、開発された4つのモデルも一気に公開せず、2019年2月、5月、8月と段階的に公開されました。 現在では、さらにバージョンアップされたGPT-3も発表されています。 GPT-2はTransformerをベースとしたテキスト生成モデルであり、与えられたテキストの単語を元に、逐次的に次の単語を予測します(図2は、「今日は」と「良い」という単語がGPT-2に与えられて、その単語群に続く単語を予測し、予測した単語とその前までに出現していた単語を元にさらに次の単語を予測しています)。 図2. GPT-2でのテキスト生成イメージ GPT-2の詳細について今回は割愛しますが、興味がある方は、Jay Alamma...
</div><div class="ui-feed-item__date" title="2021-02-03 03:00:00">1年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/flutter/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/flutter/">Flutterで高速開発したAnewsモバイルアプリ</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
はじめに 2020年11月にリリースされた、ストックマークのAnewsのモバイルアプリケーションにはFlutterが利用されています。本記事では、Flutterをなぜ採用したのか、どのような点に課題があり、どのように工夫していったのか、という開発現場の知見について紹介いたします。(本記事は、実際に開発を行った祖父江 聡士さん・海老原 隆太さんへの社内インタビューを元に執筆されています） Flutterで開発されたAnewsの画面イメージ Flutterとは Google社によって開発されているオープンソースのフレームワークです。クロスプラットフォーム向けの開発が可能であり、iOSやAndroidといったモバイルアプリケーションに多く利用されますが、Windows/Mac/Linuxといったプラットフォームのアプリケーションも開発可能です。 StockmarkにおけるFlutterの適用領域 Anewsは日々のニュースをユーザの趣向にあわせて提供するプロダクトです。システム構成は、バックエンドに備えるREST APIをフロントエンド側から叩いて、ユーザ側の画面を生成する、というシンプルな構成となっています。この、AnewsのモバイルアプリケーションにFlutterを利用しています。 AnewsのWebアプリケーションでは、ユーザがブラウザ上でURLをクリック/タップした場合に、別タブで表示しますが、モバイルアプリケーションでは内部のWebViewに表示するようにしています。これは、見ているページをマークする・ページに対してコメントするなどの付加機能を、ユーザが簡単に利用できるためであり、ユーザ価値を高めています。 技術選定の経緯 もともと、以下の方針が候補として上がりました。 WebView Native + WebView Native また、同じく iOS -&gt; Android といったように別々に作るか、クロスプラットフォームで同時に作るかという観点がありました。 このときの社内体制として、iOS/Androidのネイティブ開発の経験が十分にあるメンバーはいませんでした。そのため、Nativeで別々に作る場合には、学習コスト含め、ある程度の期間が必要な点が見込まれます。 クロスプラットフォームで開発する場合も、専用の言語やフレームワークの学習コストが発生しますが...
</div><div class="ui-feed-item__date" title="2020-12-23 03:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/202012_ner_dataset/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/202012_ner_dataset/">Wikipediaを用いた日本語の固有表現抽出データセットの公開</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
ML事業部の近江崇宏です。 ストックマークではプロダクトで様々な自然言語処理の技術を用いていますが、その中のコア技術の一つに固有表現抽出があります。固有表現抽出はテキストの中から固有表現（固有名詞）を抽出する技術で、例えば「Astrategy」というプロダクトでは、固有表現抽出を用いてニュース記事の中から企業名を抽出しています。（企業名抽出については過去のブログ記事を参考にしてください。） 一般に、固有表現抽出を行うためには、大量のテキストに固有表現をアノテーションした学習データをもとに機械学習モデルの学習を行います。今回、ストックマークは固有表現抽出のための日本語の学習データセットを公開いたします！ご自由にお使いいただければと思います！ レポジトリ：https://github.com/stockmarkteam/ner-wikipedia-dataset 固有表現をハイライトしたサンプル：https://stockmarkteam.github.io/ner-wikipedia-dataset/index.html このデータセットは日本語版Wikipediaから抜き出した文に対して、固有表現のタグ付けを行なったもので、全体で約4千件ほどとなっています。アノテーションを行なった固有表現のカテゴリーと固有表現数は下のようになっています。分類は関根の拡張固有表現階層を参考にしました。 タイプ 固有表現数 備考 人名 2382 法人名 2311 法人または法人に類する組織 政治的組織名 707 政治的組織名、政党名、政府組織名、行政組織名、軍隊名、国際組織名 その他の組織名 658 競技組織名、公演組織名、その他 地名 1443 施設名 512 製品名 576 商品名、番組名、映画名、書籍名、歌名、ブランド名等 イベント名 526 今後、このデータセットを用いた実験やスクリプトなども公開できればと考えています。</div><div class="ui-feed-item__date" title="2020-12-15 03:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" 
href="https://tech.stockmark.co.jp/blog/202010_tpu_gcp_system/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/202010_tpu_gcp_system/">Cloud TPUを用いたBERT推論処理基盤の開発</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
ML事業部の近江崇宏です。 Stockmarkでは日々、膨大な数のニュース記事に対してBERTの推論処理を行なっています。このような重いタスクを効率的に処理するために、最近、TPUを用いたBERTの推論処理基盤をGoogle Cloud Platform上に構築し、運用を開始しました。その結果として、これまで1週間程度かかっていた、数千万件のデータの処理を1日以内で完了できるようになるなどの大きな効果を得られました。今回はこの取り組みについて紹介します。 はじめに 近年のニューラルネットワークの研究の発展により、画像認識や自然言語処理の様々なタスクを人間と同等もしくはそれ以上のレベルで処理できるようになりました。その結果として、ビジネスでのニューラルネットワークの利用が進んでいます。その一方で、ニューラルネットワークには、モデルの巨大さに起因して処理時間が長いという大きな問題があります。そのため、それらを適切にコントロールすることが、プロダクトでのニューラルネットワークの活用が成功するかどうかの重要な鍵になっています。 一般的には、モデルを学習するときの処理時間の長さが問題とされることが多いですが、これは推論でも大きな問題となり得ます。特にStockmarkでは、BERTと呼ばれる自然言語処理のためのニューラルネットワークを用いて、膨大な数のニュース記事に対して分類や抽出などの推論処理をしており、これにかかる時間の削減がプロダクトでの大きな課題になっています。具体的には、 新規のニュース記事（数万件）に対する日次のバッチ処理 新たなモデルがプロダクトに追加された場合や、アルゴリズムの変更や学習データの追加により既存のモデルが更新された場合に行われる、データベースに保存されている過去のニュース記事（数千万件）に対する全件処理 などの日々のオペレーションでBERTの推論処理を行なっています。そのため、このような大規模なデータに対して効率的に推論処理をするための強力な処理基盤が必要になりました。 StockmarkではこれまでBERTの推論を主にGPUを用いて行なってきましたが、Googleが開発した行列演算などの機械学習の処理に特化したチップであるTPUを用いて、データ処理を効率化する取り組みを最近始めました。そして、新たな処理システムをGoogle Cloud Pla...
</div><div class="ui-feed-item__date" title="2020-11-04 03:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/tpu_vs_gpu_en/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/tpu_vs_gpu_en/">TPU VS GPU(English Edition)</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
Introduction In this era, any machine learning enthusiast who has been trying to catch a good performance by training neural networks on a huge amount of data has struggled with the amount of time that the deep neural network models take for training. In addition, deep learning models are in dire need of hardware resources. Further, it is better to use Graphics Processing Unit (GPUs) instead of Central Processing Unit (CPUs), since they are faster than CPUs for training deep neural networks.</div><div class="ui-feed-item__date" title="2020-10-30 03:00:24">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/tpu_vs_gpu_ja/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/tpu_vs_gpu_ja/">TPU VS GPU(日本語版)</a><div 
class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
はじめに (この記事の英語版はTPU VS GPU(English Edition)にあります。) Machine Learning部門の江間見です。ストックマークでは、自然言語処理技術の研究開発を行っています。 昨今、大規模データでニューラルネットワークを訓練し良い結果を得ようとするならば、深層学習モデルの訓練にかかる時間の膨大さに誰もが悩まされたことがあるかと思います。さらに、深層学習モデルはハードウェアのリソースを多く必要とします。 深層学習モデルの学習では、計算の特性上、CPU（Central Processing Unit）より GPU（Graphics Processing Unit）が高速であるため、GPUが推奨されます。しかし、GPU以外の選択肢として、TPU(Tensor Processing Unit)があります。 そこで、本記事では、自然言語処理のタスクで深層学習モデルの学習におけるTPUとGPUを比較していきます。 Processsing Unitの紹介 GPU GPUは、グラフィック処理や数値計算等で使用される専用メモリを備えた特殊なプロセッサです。GPUは単一処理に特化しており、SIMD（Single Instruction and Multi Data）アーキテクチャ用に設計されています。そのため、GPUは同種の計算を並列に実行(単一の命令で複数のデータを処理)します。 特に深層学習ネットワークでは数百万のパラメータを扱うので、多数の論理コア（演算論理ユニット（ALU）制御ユニットとメモリキャッシュ）を採用しているGPUが重要な役割を果たします。GPUには多数のコアが含まれているため、複数の並列処理を行列計算で高速に計算可能です。 TPU TPUは、Google社から2016年5月、Google I/O（Google社が毎年開催している開発者向けカンファレンス）で発表されました(すでに同社のデータセンター内で1年以上使用されていたとのことです)。 TPUは、ニューラルネットワークや機械学習のタスクに特化して設計されており、2018年からはサードパーティでも利用可能です。 Google社は、Googleストリートビューのテキスト処理にTPUを使用してストリートビューのデータベース内のすべてのテキストを5日間で発見し、Google Phot...
</div><div class="ui-feed-item__date" title="2020-10-30 03:00:24">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/how_we_succeeded_in_big_rewriting/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/how_we_succeeded_in_big_rewriting/">ビッグリライトでシステム刷新した秘訣 ~ Anewsの成功事例から ~</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
はじめに ストックマークが提供するプロダクトであるAnewsにおいて、ビッグリライトによるフロントエンド・バックエンドの両方を含むアーキテクチャ刷新を成功させました。一般にビッグリライトは、ハイリスク・ハイリターンであり、難易度も高いと言われていますが、大きなトラブルもなく、かつお客様評価も高い状態を実現しています。 Anewsリニューアル後の画面イメージ 本記事では、なぜビッグリライトを選択したのか、何が要因となって成功に至ったのか、といった事項について、開発チームで振り返りした中からいくつかの要因を紹介いたします。 アーキテクチャ刷新の背景 Anewsは、新規Feedを最適化して提供するプロダクトで、2020/8時点では累計1500社のお客様に利用されています。(参考：導入事例) スタートアップのプロダクトでは、顧客の声に耳を傾けながら、大小あるピボットを積み重ねて、洗練されたプロダクトを開発・提供していきます。Anewsも例にもれず、細かな変更の積み重ねを繰り返してきました。幸いなことに多くのお客様に利用いただいておりましたが、より高い価値を提供するためには、プロダクトを大きく変更する必要がでてきました。 そこで、2020/1に大規模なシステムリニューアルを決断しました。 なぜビッグリライトの選択したのか？ 基本的なプロダクトのベース機能は、リニューアル前後で同一です。ベース機能は同一ですが、今回のリニューアルでは、ニュースフィード画面の大きな変更を加えます。 このような状況下でのベースアーキテクチャ刷新の方法には、ビッグリライト・リアーキテクティング・リファクタリングなどいくつかのアプローチがあります。（参考：レガシーソフトウェア改善ガイド） Anewsでは前述の通り、ハイリスク・ハイリターンであるビッグリライトを選択しました。一般に、ビッグリライトは、既存プロダクトと並行開発・運用する必要もあるため、リソース的な制約もあり、難易度があがります。しかし、成功した場合には、顧客向けの提供したい価値の最大化に加えて、これまでの技術的負債の解消も狙えます。 そこで、Anewsではビッグリライトを選択しました。もちろん、単に選択したのではなく、いくつかの工夫を加えることによって、成功確度を戦略的に高めています。以下ではそのアプローチについて紹介いたします。 ビッグリ...
</div><div class="ui-feed-item__date" title="2020-09-15 03:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/security_efforts/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/security_efforts/">ストックマークにおけるB2B SaaSセキュリティへの取り組み</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
こんにちは、ストックマークでSREを担当している松下です。 ストックマークでは企業向けの情報収集・企業分析・営業支援サービス(Anews, Astrategy, Asales)を運営しており、導入を検討されているお客様よりセキュリティの取り組みに関してお問い合わせをいただくことが多々あります。 お客様のセキュリティ基準をプロダクトが満たせるかどうかは、ストックマークにとっても最重要課題であり、ストックマークのセキュリティ向上への姿勢をより分かりやすく示すために、8月にはISMS認証を取得しました。 今回はISMS認証取得を記念して、私が担当しているAsalesを例にしながら、これまでにストックマークが行ってきたセキュリティ対策の一部をざっくりとご紹介させていただこうと思います。 Asalesについて Asalesはセールスなどの提案資料や社内資料を自然言語処理技術で学習・解析し、売上拡大のために必要な社内ナレッジを共有・レコメンドする営業支援サービスです。 蓄積された提案書を&quot;言葉のAI&quot;が解析することで、提案経験のある社内エキスパートを見つけ出せたり、顧客に響く提案を作成するヒントを得る機会を創出します。 図1: Asalesの機能 提案資料の作成をイメージして「Asalesを利用する流れ」を簡単にご説明すると、 エンドユーザーはAsalesに提案資料や社内資料をアップロードする。 アップロードされたファイルは機械学習処理により学習・解析され、その結果が保存される。 エンドユーザーがAsalesからキーワードや作成者、商材、業界などを指定して検索を行うと、保存された学習・解析結果から最適なスライドを探し当てることができる。 となりますが、Asalesを利用して作成した資料をAsalesにアップロードして、それがまた誰かの役に立って新しい資料がAsalesにアップロードされて、というサイクルが続けば、学習・解析の効果がより高まって「セールスの永久機関になり得るな」と考えたりしています。 セキュリティ対策の検討ポイント そんなAsalesですが、お客様から「クラウドにアップロードしたデータに第三者がアクセスできない仕組みがあるか」というお問い合わせをよくいただきます。 お問い合わせをいただく中には施設・設備などへの物理的なアクセスを含んでいることがありますが、こちら...
</div><div class="ui-feed-item__date" title="2020-09-03 03:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/202007_company_entities_recognition/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/202007_company_entities_recognition/">BERTによるニュース記事の構造化：企業名抽出</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
はじめに Machine Learning部門の近江です。ストックマークでは、自然言語処理技術の研究開発を行っています。 先日、弊社のTech Blogにて弊社が公開している言語モデルを紹介しました。 ストックマークが公開した言語モデルの一覧と振り返り 今回は、言語モデルがプロダクトにおいて実際にどのように利用されているかについての一例を紹介します。 ニュース記事の構造化 マーケティング、新規事業開発などの調査業務では、調査を行う人が書籍、ニュース記事、ホームページなどの情報を網羅的に調べ、整理し、報告書などにまとめていきます。その際に扱う情報は膨大であり、そのため調査業務には多くの時間と労力がかかります。 弊社のプロダクトである「Astrategy」は機械学習を用いてニュース記事から特徴となる情報を抽出し、構造化することで、大量のニュース記事を効率的に俯瞰し、さらに新規事業開発などに繋がりうる情報の発見を促進することを目的としたものです。 Astrategyではニュース記事の構造化の一つとして、ニュース記事に現れる企業の名称を抜き出すということを行っています。これは、市場調査において市場にどのようなプレイヤー（企業）が存在するのかという情報は、非常に重要であるからです。今回は、この「ニュース記事からの企業名抽出」を例にして、言語モデルを用いた機械学習についての弊社の取り組みを紹介します。 企業名抽出の難しさ 機械学習でニュース記事から企業名を抽出すると聞いて、多くの人は「これは簡単なタスクだ」と思うのではないでしょうか？このタスクは人間にとっては非常に簡単です。しかしながら、以下でわかるように、これをコンピュータにやらせるのは意外と難しいものです。 企業名をテキストから抽出する最も単純なアプローチは、企業名を集めた辞書を用意しておき、辞書に含まれている企業名が文章中に含まれていれば、それを企業名と見なすというものです（辞書方式）。企業名の辞書としては、国税庁が公開している日本に存在する全ての法人を登録したデータベース（https://www.houjin-bangou.nta.go.jp/）があります。これを用いて、実際に次の文章に対して辞書方式の企業名抽出をしてみましょう。 「ストックマーク株式会社では現在、エンジニアを募集しています。」 これを見た時、多くの人...
</div><div class="ui-feed-item__date" title="2020-07-15 03:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/aws_denshosen_aiboke/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/aws_denshosen_aiboke/">「電笑戦 ~ AI は人を笑わせられるのか ?」に出場します！</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">こんにちは、ストックマークでPR担当している中野です。 AIに人は笑わせられるのか…。 9月開催の「AWS Summit」で行われる 「電笑戦 ~ AI は人を笑わせられるのか ?」の挑戦者 として、当社のAIが出場します！ 1枚の画像に対して一言コメントでボケて、笑いを取るコンテンツです。 「AWS Summit」の開催に先駆けて、画像に対してAIがボケてる様子を記事にして頂きました！ 弊社 森長が、技術解説とともに、実際にAIが繰り出すボケをいくつか紹介します！ぜひチェックしてみてください。 9月8日(火)～9月30日(水)に開催される「AWS Summit Online」の本番もご期待ください！ 記事掲載：AWSウェブマガジン「builders.flash」 電笑戦 ~ AIは人を笑わせられるのか 第 2 回 電笑戦の背景と挑戦者</div><div 
class="ui-feed-item__date" title="2020-07-01 15:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/list_of_the_published_learning_models/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/list_of_the_published_learning_models/">ストックマークが公開した言語モデルの一覧と振り返り</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
こんにちは、Machine Learning部門の森長と申します。 Machine Learning部門は、プロダクト適用を目指した基礎研究&amp;基礎研究のプロダクト適用の二軸を担当しています。基礎研究では、言語モデルの作成、文章のカテゴリ分類・クラスタリング、要約の検証等、プロダクトへの適用を見据えて研究テーマを設定しています。また、自然言語処理の盛り上がりに少しでも貢献できればと考え、言語モデルの公開を行っていますので、もしよろしければ使ってみてください。 今回は、弊社で公開している言語モデルについて書いていきます。 言語モデルとは 言語モデルにも色々な種類のモデルがあり、一口でこれというのは難しいですが、簡単に言うとすると、「単語列に対して確率を計算するモデル」です。 厳密には各言語モデルで目的が違うため、呼称が少しずつ異なりますが、本投稿では言語モデルという表現で統一させていただきます。 言語モデルを利用することで、例えば、文章の生成や単語の意味的な近さの計算を行えます。 弊社では、これらの言語モデルを組み合せることで、ビジネス文章の解析・構造化(文の分類やクラスタリング、企業名抽出等)を行っています。 弊社で公開している言語モデル一覧 弊社では、Qiitaで紹介記事を書き、以下の言語モデルを公開しています。 言語モデル Qiita公開リンク ELMo 大規模日本語ビジネスニュースコーパスを学習したELMo（MeCab利用）モデルの紹介 BERT 大規模日本語ビジネスニュースコーパスを学習したBERT事前学習済（MeCab利用）モデルの紹介 XLNet 大規模日本語ビジネスニュースコーパスを学習したXLNet（MeCab+Sentencepiece利用）モデルの紹介 ALBERT 大規模日本語ビジネスニュースコーパスを学習したALBERT（MeCab+Sentencepiece利用）モデルの紹介 公開している学習モデルの詳しい説明はQiita記事を参照いただければと思います。 今回はせっかくなので、言語モデル作成当時の経緯等を順に振り返ります。 ELMo 2018年11月某日.. 森長：「記事の分類の分類タスクの精度向上が頭打ちになってきた。。。記事中の「ライオン」という文字列が「企業のライオン」さんなのか「大西ライオン」さんなのか「百獣の王のライオン」さんなの...
</div><div class="ui-feed-item__date" title="2020-06-26 03:00:24">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/mlops/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/mlops/">BERTを使ったMLバッチ処理実サービスのアーキテクチャとMLOpsの取り組み</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
こんにちは、Development部門に所属しているSREの佐藤と申します。 Development部門では複数プロダクト共通の基盤構築や、新技術の検証、インフラ整備などを幅広く担当しています。これまでストックマークではCI/CD基盤の構築やAWS上で構築するインフラのコード化、ニュース収集基盤のアーキテクチャの改善や運用負荷軽減から、製品利用状況のデータ分析基盤構築などに取り組んできました。 今日はAstrategyという製品でのMLOpsの取り組みについて話します。 Astrategyについて Astrategyは国内外Webメディアを対象として情報を収集・構造化し、調査・報告業務を包括的にサポートする検索プラットフォームです。 図1: 「言葉のAI」自然言語解析を用いたオープンデータ解析ツール 複数の分析画面を提供しており、目的に応じて異なる観点で市場変化や競合動向を可視化できます。 図2: Astrategyの分析画面 人力では約50~100記事（期間:1カ月）の調査が限界ですが、Astrategyを利用することで約5,000記事を俯瞰し構造化することでこれまでにたどりつけなかった情報の調査が可能になります。 図3: Astrategyが提供する価値とは Astrategyのシステム構成 以下がAstrategyのシステム構成です。 ユーザーがアクセスした時に動作する「オンライン処理」システムと、夜間や早朝にオンライン処理から参照するデータ生成する「バッチ処理」システムで構成されています。 図4 Astrategyのシステム構成 今日私が話すのは機械学習バッチ処理（以降MLバッチ処理）システムのMLOps取り組みについてです。 MLバッチ処理 Astrategyのバッチ処理では、弊社の独自クローラーが約3万メディアから収集した1日約30万件、合計約2000万件のニュース記事を、「業界」、「地域」などの分類、「企業名の抽出」など10種類の機械学習ジョブで推論を行い、記事にラベル付けをします。 図5: バッチ処理概要 ラベル付けされた記事データは検索サーバー (Elasticsearch)のインデックスに登録され、アプリケーションの各分析画面 (図2)から呼び出されます。 MLモデルについて バッチ処理ではBERTを応用して作成したMLモデルを各タスク用にチュー...
</div><div class="ui-feed-item__date" title="2020-05-31 21:00:00">2年前</div></div></div><div class="ui-feed-item"><a class="ui-feed-item__og-image" href="https://tech.stockmark.co.jp/blog/blogstart/"><img src="../../images/alternate-feed-image.png" loading="lazy" decoding="async" alt="記事のアイキャッチ画像" width="256" height="256"></a><div class="ui-feed-item__content"><a class="ui-feed-item__title" href="https://tech.stockmark.co.jp/blog/blogstart/">ブログはじめました</a><div class="ui-feed-item__blog-title">Stockmark Tech Blog</div><div class="ui-feed-item__summary">
こんにちは、ストックマーク CTO有馬です。 この度、テックブログをはじめることにしました。 創業してからあっという間に3年半が経ち、Anewsに至ってはおかげさまで1500社様に活用いただけるような大きなAI SaaSプロダクトにまで成長しました。 AIという高次元でハイカロリーな計算処理をSaaS内で実用化し顧客価値につなげるには、不断の学習と成長痛が伴います。 サービス立ち上げ当初は、精度がなかなか出ず赤子のような出力になったり、急増するユーザ数にアーキテクチャが追いつかず復旧のために3日間徹夜してしまったり、深夜にAIが暴走していて朝起きたら100万円規模のサーバー費課金をくらったり・・・ ただ、やればやるほど、これまでのITにはない価値と興奮をAIは創出できるという手応えを感じるようになりました。 創業時点からは考えもつかなかったほどの優秀なメンバーが集まり、予想の斜め上を行くような技術知見が多く集まるようになりました。社内だけにとどめておくのは勿体無いと感じ、公開したいと思うに至りました。 隔週程度を目標に、投稿していきたいと思いますので、よろしければ読んでいただければと思います。 よろしくお願い致します。</div><div class="ui-feed-item__date" title="2020-05-31 15:00:00">2年前</div></div></div></div></div></section></main><footer role="contentinfo" class="ui-section-footer"><div class="ui-layout-container"><div class="ui-section-footer__layout ui-layout-flex"><p class="ui-section-footer--copyright ui-text-note"><a class="ui-text-note" href="https://github.com/yamadashy/"><small>@yamadashy</small></a></p><a href="https://github.com/yamadashy/tech-blog-rss-feed/" role="link" 
aria-label="#" class="ui-text-note"><small>GitHub</small></a></div></div></footer></body></html>